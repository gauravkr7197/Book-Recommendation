{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Title: Paris Talks\n",
      "Enter Author: 'Abdu'l-Baha\n",
      "************** Searching for Book *******************\n",
      "Completed in 0.162 seconds...\n",
      "*********** Finding Recommendations ***************\n",
      "Completed in 0.619 seconds...\n",
      "************* Your Recommendations ***************\n",
      "                                              book_name             author\n",
      "3                                           Paris Talks       'Abdu'l-Baha\n",
      "2                            Foundations of World Unity       'Abdu'l-Baha\n",
      "4                     The Secret of Divine Civilization       'Abdu'l-Baha\n",
      "1800                                  The Lord of Glory     Arno Gaebelein\n",
      "1037                            The Master's Indwelling      Andrew Murray\n",
      "5                                A Traveler's Narrative       'Abdu'l-Baha\n",
      "1799                                Studies in Prophecy  Arno C. Gaebelein\n",
      "1038                       The Ministry of Intercession      Andrew Murray\n",
      "6                                    Baha'i World Faith       'Abdu'l-Baha\n",
      "2231                     Epistle to the Son of the Wolf        Baha'u'llah\n",
      "1169  Original sonnets on various subjects; and odes...        Anna Seward\n",
      "8                             Memorials of the Faithful       'Abdu'l-Baha\n",
      "1241                               Power Through Repose  Annie Payson Call\n",
      "2362                                           Sketches  Benjamin Disraeli\n",
      "743                            The Minister and the Boy        Allan Hoben\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data-23k.csv\",nrows=2500,engine='python')\n",
    "attempts=5\n",
    "for attempt in range(attempts):\n",
    "    try:\n",
    "        usr_title = input(\"Enter Title: \")\n",
    "        usr_author = input(\"Enter Author: \")\n",
    "        found = data[(data.book_name == usr_title) & (data.author == usr_author)]\n",
    "        found_book = found['ID']\n",
    "        id_target = found_book.tolist()[0]\n",
    "    except IndexError:\n",
    "        print (\"**** Title and/or Author Incorrect or Book is not in corpus****\\nPlease try again\")\n",
    "            # sys.exit(1)\n",
    "    else:\n",
    "        print (\"************** Searching for Book *******************\")\n",
    "        break\n",
    "    # Start timer\n",
    "# Paris Talks\n",
    "# 'Abdu'l-Baha\n",
    "# status = \"**************** Adjusting Data *******************\"\n",
    "start_time = time.time()\n",
    "# print status\n",
    "data = data.drop('>', 1)\n",
    "data = data.drop('(', 1)\n",
    "data = data.drop('[', 1)\n",
    "data = data.drop('{', 1)\n",
    "data = data.drop('#', 1)\n",
    "data = data.drop('&', 1)\n",
    "data = data.drop('/', 1)\n",
    "data = data.drop('\\\\', 1)\n",
    "data = data.drop('*', 1)\n",
    "data = data.drop('@', 1)\n",
    "data = data.drop('_', 1)\n",
    "data = data.drop('^', 1)\n",
    "\n",
    "# data = pd.concat([data, pd.get_dummies(data['Cluster'])], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data['smallClusterId'], prefix=\"general\")], axis=1)  #and for each cluster\n",
    "data = pd.concat([data, pd.get_dummies(data['mediumClusterId'], prefix=\"medium\")], axis=1) \n",
    "data = pd.concat([data, pd.get_dummies(data['largeClusterId'], prefix=\"specific\")], axis=1) \n",
    "data = pd.concat([data, pd.get_dummies(data['author'])], axis=1)  #now you have a binary variable for each author\n",
    "\n",
    "titles = data['book_name']\n",
    "authors = data['author']\n",
    "IDs = data['ID']\n",
    "\n",
    "data = data.drop('ID', 1)\n",
    "data = data.drop('book_name', 1)\n",
    "data = data.drop('mediumClusterId', 1)\n",
    "data = data.drop('smallClusterId', 1)\n",
    "data = data.drop('largeClusterId', 1)\n",
    "data = data.drop('author', 1)\n",
    "data = data.drop('filename', 1)\n",
    "data = data.fillna(0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "# data.to_csv(\"Normalized output.csv\")\n",
    "data['ID'] = IDs  #had to remove this earlier because we didn't want IDs to be scaled with the other columns \n",
    "\n",
    "print(\"Completed in %.3f seconds...\" % (time.time() - start_time))\n",
    "\n",
    "status = \"*********** Finding Recommendations ***************\"\n",
    "print (status)\n",
    "start_time = time.time()\n",
    "\n",
    "example = data[data['ID']==id_target]\n",
    "example = example.drop('ID', 1)\n",
    "data = data.drop('ID', 1)\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(5)\n",
    "neigh = neigh.fit(data)\n",
    "\n",
    "# print \"example \", example\n",
    "output = neigh.kneighbors(example, 15)\n",
    "a = output[0]\n",
    "b = output[1]\n",
    "# print \"Distance \", a\n",
    "# print \"Nearest Neighbor \", b\n",
    "b = b.tolist()\n",
    "b = b[0]\n",
    "\n",
    "fulldata = data\n",
    "fulldata['author'] = authors\n",
    "fulldata['book_name'] = titles\n",
    "results = data.iloc[b,:]\n",
    "# print results.shape\n",
    "results = results[['book_name','author']]\n",
    "print(\"Completed in %.3f seconds...\" % (time.time() - start_time))\n",
    "\n",
    "status = \"************* Your Recommendations ***************\"\n",
    "print (status)\n",
    "print (results)\n",
    "\n",
    "# Paris Talks\n",
    "# 'Abdu'l-Baha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status = \"**************** Adjusting Data *******************\"\n",
    "start_time = time.time()\n",
    "# print status\n",
    "data = data.drop('>', 1)\n",
    "data = data.drop('(', 1)\n",
    "data = data.drop('[', 1)\n",
    "data = data.drop('{', 1)\n",
    "data = data.drop('#', 1)\n",
    "data = data.drop('&', 1)\n",
    "data = data.drop('/', 1)\n",
    "data = data.drop('\\\\', 1)\n",
    "data = data.drop('*', 1)\n",
    "data = data.drop('@', 1)\n",
    "data = data.drop('_', 1)\n",
    "data = data.drop('^', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([data, pd.get_dummies(data['Cluster'])], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data['smallClusterId'], prefix=\"general\")], axis=1)  #and for each cluster\n",
    "data = pd.concat([data, pd.get_dummies(data['mediumClusterId'], prefix=\"medium\")], axis=1) \n",
    "data = pd.concat([data, pd.get_dummies(data['largeClusterId'], prefix=\"specific\")], axis=1) \n",
    "data = pd.concat([data, pd.get_dummies(data['author'])], axis=1)  #now you have a binary variable for each author\n",
    "\n",
    "titles = data['book_name']\n",
    "authors = data['author']\n",
    "IDs = data['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('ID', 1)\n",
    "data = data.drop('book_name', 1)\n",
    "data = data.drop('mediumClusterId', 1)\n",
    "data = data.drop('smallClusterId', 1)\n",
    "data = data.drop('largeClusterId', 1)\n",
    "data = data.drop('author', 1)\n",
    "data = data.drop('filename', 1)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 0.907 seconds...\n",
      "*********** Finding Recommendations ***************\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "# data.to_csv(\"Normalized output.csv\")\n",
    "data['ID'] = IDs  #had to remove this earlier because we didn't want IDs to be scaled with the other columns \n",
    "\n",
    "print(\"Completed in %.3f seconds...\" % (time.time() - start_time))\n",
    "\n",
    "status = \"*********** Finding Recommendations ***************\"\n",
    "print (status)\n",
    "start_time = time.time()\n",
    "\n",
    "example = data[data['ID']==id_target]\n",
    "example = example.drop('ID', 1)\n",
    "data = data.drop('ID', 1)\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(5)\n",
    "neigh = neigh.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 0.329 seconds...\n",
      "************* Your Recommendations ***************\n",
      "                             book_name                        author\n",
      "3                          Paris Talks                  'Abdu'l-Baha\n",
      "2           Foundations of World Unity                  'Abdu'l-Baha\n",
      "4    The Secret of Divine Civilization                  'Abdu'l-Baha\n",
      "5               A Traveler's Narrative                  'Abdu'l-Baha\n",
      "6                   Baha'i World Faith                  'Abdu'l-Baha\n",
      "8            Memorials of the Faithful                  'Abdu'l-Baha\n",
      "743           The Minister and the Boy                   Allan Hoben\n",
      "491                  Samuel Rutherford               Alexander Whyte\n",
      "7              Some Answered Questions                  'Abdu'l-Baha\n",
      "874             The Ascent of the Soul             Amory H. Bradford\n",
      "996            Letters to Dead Authors                   Andrew Lang\n",
      "17                      National Being  (A.E.)George William Russell\n",
      "599                  A Celtic Psaltery        Alfred Perceval Graves\n",
      "311               Americans and Others                Agnes Repplier\n",
      "351                              Poems                   Alan Seeger\n"
     ]
    }
   ],
   "source": [
    "# print \"example \", example\n",
    "output = neigh.kneighbors(example, 15)\n",
    "a = output[0]\n",
    "b = output[1]\n",
    "# print \"Distance \", a\n",
    "# print \"Nearest Neighbor \", b\n",
    "b = b.tolist()\n",
    "b = b[0]\n",
    "\n",
    "fulldata = data\n",
    "fulldata['author'] = authors\n",
    "fulldata['book_name'] = titles\n",
    "results = data.iloc[b,:]\n",
    "# print results.shape\n",
    "results = results[['book_name','author']]\n",
    "print(\"Completed in %.3f seconds...\" % (time.time() - start_time))\n",
    "\n",
    "status = \"************* Your Recommendations ***************\"\n",
    "print (status)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
